---
title: "Group 1 Parkinsons Data Set"
format: html
editor: visual
---

## Group 1

Tara Dehdari, Patricio Martinez, Duy Nguyen

## Problem Statement:



#### Load Libraries

```{r}
library(caret)
library(randomForest)
library(tidyverse)
library(ggplot2)
library(earth)
library(kernlab)
library(dplyr)
library(corrplot)
theme_set(theme_minimal())

#Set seed to reproduce samples
seed <- 123
```

#### Load Data

```{r}
df <- read.csv("parkinsons_updrs.data.csv")
head(df)

```

## Exploratory Data Analysis:

#### Data Types

```{r}
str(df)
```
```{r}
summary(df)
```
```{r}
dim(df)
```

#### Missing Values

```{r}
sum(is.na(df))
```

#### Visualizations

```{r}
# Age distribution
ggplot(df, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Age Distribution of Patients", x = "Age", y = "Count")

# Total UPDRS distribution
ggplot(df, aes(x = total_UPDRS)) +
  geom_histogram(binwidth = 5, fill = "green", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Total UPDRS Scores", x = "Total UPDRS", y = "Count")

# Age vs. Total UPDRS
ggplot(df, aes(x = age, y = total_UPDRS)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Age vs. Total UPDRS", x = "Age", y = "Total UPDRS")
```
```{r}
# Count the number of males and females
sex_count <- df %>% 
  group_by(sex) %>%
  summarise(count = n())

# Convert 'sex' to factor for better labeling
sex_count$sex <- factor(sex_count$sex, labels = c("Female", "Male"))

# Create a bar plot for the distribution of males and females
ggplot(sex_count, aes(x = sex, y = count, fill = sex)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Distribution of Males and Females", x = "Sex", y = "Count") +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue"))
```
## Preprocessing

#### Normalize the Dataset

```{r}
# gather numeric columns
numeric_cols <- sapply(df, is.numeric)

# normalizing the numerical features
df[numeric_cols] <- lapply(df[numeric_cols], scale)
```

#### Resampling Female and Male

```{r}
# determine the minimum count
min_count <- min(sex_count$count)

# downsample the majority class 
df_downsample <- df %>%
  group_by(sex) %>%
  sample_n(min_count)

# Visualizing new amount of male and female

# Count the number of males and females after downsampling
sex_count_downsampled <- df_downsample %>%
  group_by(sex) %>%
  summarise(count = n())

# Convert 'sex' to factor for better labeling
sex_count_downsampled$sex <- factor(sex_count_downsampled$sex, labels = c("Female", "Male"))

# Create a bar plot for the distribution of males and females after downsampling
ggplot(sex_count_downsampled, aes(x = sex, y = count, fill = sex)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Distribution of Males and Females after Downsampling", x = "Sex", y = "Count") +
  scale_fill_manual(values = c("Female" = "pink", "Male" = "blue"))
```

#### Heatmap Correlation

```{r}
correlations <- cor(df)

corrplot(correlations, order = "hclust")

print(correlations)
```
##### Removing High Correlations

```{r}

# find highly correlated predictors
highCorr <- findCorrelation(correlations, cutoff = 0.80)
cat("The amount of high correlations:", length(highCorr), "\n")
cat("\n")
cat ("Values with high correlations: \n")
cat(highCorr)

```
```{r}
# removing high correlations
filtered_df <- df[,-highCorr]

# correlation heatmap again 
correlationsFiltered <- cor(filtered_df)
corrplot(correlationsFiltered, order = "hclust")
```
```{r}
# Print dimensions of filtered dataset and original dataset
cat("Original data dimensions:", dim(df), "\n")
cat("Filtered data dimensions:", dim(filtered_df), "\n")
```

#### Outlier Check

Calculating what would be considered an outlier shows that there are quiet a few but looking at the boxplots nothing is significant enought to withdraw from the dataset. 

```{r}
# Boxplot for each numerical variable
boxplot(df[,numeric_cols], outline=TRUE, col="lightblue", main="Boxplot of Numerical Variables")

# Function to detect outliers using IQR method
detect_outliers <- function(x) {
  q1 <- quantile(x, 0.25)
  q3 <- quantile(x, 0.75)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  outliers <- x < lower_bound | x > upper_bound
  return(outliers)
}

# Apply the function to each numerical variable
outliers <- apply(df[,numeric_cols], 2, detect_outliers)

# Count the number of outliers for each variable
outlier_counts <- colSums(outliers)
outlier_counts
```

#### Visualizing Target Variable (total_UPDRS (Unified Parkinson's Disease Rating Scale Score))

```{r}
# Visualize the distribution of total_UPDRS with density plot
ggplot(filtered_df, aes(x = total_UPDRS)) +
  geom_density(fill = "green", color = "black") +
  theme_minimal() +
  labs(title = "Density Plot of Total UPDRS Scores", x = "Total UPDRS", y = "Density")

```
#### Relationships between target and predictor variables

```{r}
# Select predictor variables (all columns except total_UPDRS)
predictor_vars <- filtered_df[, !colnames(filtered_df) %in% "total_UPDRS"]

# Create scatter plots for each predictor variable against total_UPDRS
for (var in colnames(predictor_vars)) {
  p <- ggplot(filtered_df, aes_string(x = var, y = "total_UPDRS")) +
    geom_point(alpha = 0.5) +
    theme_minimal() +
    labs(title = paste("Scatter Plot of", var, "vs. Total UPDRS"), 
         x = var, y = "Total UPDRS")
  
  print(p)
}
```


## Data Splitting:

```{r}
# Split the data into training and test sets (80% train, 20% test)
set.seed(123)
trainIndex <- createDataPartition(filtered_df$total_UPDRS, p = 0.8, list = FALSE)
df_train <- filtered_df[trainIndex, ]
df_test <- filtered_df[-trainIndex, ]

# Print dimensions of training and test sets
cat("Training data dimensions:", dim(df_train), "\n")
cat("Test data dimensions:", dim(df_test), "\n")

```

## Model Building:

#### Linear Regression

```{r}
# train linear moddel
linear_model <- lm(total_UPDRS ~ .,
                   data = df_train)

# predict linear model
linear_predictions <- predict(linear_model, 
                              df_test)

```

## Evaluation Metrics

```{r}
# Initialize empty dataframe to store results
testResults <- data.frame(Model = character(),
                          RMSE = numeric(),
                          MAE = numeric(),
                          Rsquared = numeric(),
                          stringsAsFactors = FALSE)

# Function to calculate evaluation metrics
evaluate_model <- function(true_values, predictions) {
  rmse <- sqrt(mean((predictions - true_values)^2))
  mae <- mean(abs(predictions - true_values))
  rsquared <- 1 - sum((predictions - true_values)^2) / sum((true_values - mean(true_values))^2)
  return(c(RMSE = rmse, MAE = mae, Rsquared = rsquared))
}
```

#### Calculate Evaluation Metrics for Each Model

```{r}
# evaluation metrics for linear regression
linear_metrics <- evaluate_model(df_test$total_UPDRS, linear_predictions)


```

#### Store Evaluation Results in DataFrame

```{r}
# store results for linear regression
testResults <- rbind(testResults, data.frame(Model = "Linear Regression", 
                                             RMSE = linear_metrics["RMSE"], 
                                             MAE = linear_metrics["MAE"], 
                                             Rsquared = linear_metrics["Rsquared"]))


```




## Results and final selection
